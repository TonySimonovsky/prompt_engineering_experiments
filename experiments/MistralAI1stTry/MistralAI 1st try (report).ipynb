{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "22441125-7eae-4d13-b8c9-97a8fe3704f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d590fa84-64bd-49a0-8dff-72e27d7f923f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(\"../../../../settings/.env\", override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f1b3d790-68e6-4c13-9c7c-93f34f952bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown, display\n",
    "\n",
    "def printmd(string):\n",
    "    display(Markdown(string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5707ca13-b8ae-4f02-9979-bda500e68c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(0, '../../../../05 Own Solutions/AIChampTools')\n",
    "\n",
    "import importlib\n",
    "\n",
    "from AIChampTools import AIChampTools, LLMUsage, PromptEngineeringExperiment, LLMMistral, LLMOpenAI\n",
    "prevent_output = importlib.reload(sys.modules['AIChampTools'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b858d31a-47d8-48e2-b575-613d4237bd85",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = PromptEngineeringExperiment(\n",
    "    name=\"MistralAI_1st_try\",\n",
    "    logs_folder=\"../../logs/\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad9803c0-3782-49aa-a476-262bf18dd9f1",
   "metadata": {},
   "source": [
    "# Experiment Report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddc73242-a628-4203-be9c-bab85c18ed23",
   "metadata": {},
   "source": [
    "Playing around with Mistral AI models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b87f89fb-1630-4105-8902-8748502eb883",
   "metadata": {},
   "source": [
    "## Version 07"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c100eb9a-a257-4925-9bdf-9c20337dc561",
   "metadata": {},
   "source": [
    "Checking how good is Mistral in generating json and how json output affects the length of the completion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "643b1259-9db7-4f00-ae9b-88b356531d93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### Variation 1"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Messages template**: [\"[{'role': 'system', 'content': '\\\\n            Act as a professional career consultant with 20 years of experience.\\\\n            \\\\n            Your objective is to help the Human create their CV.\\\\n            \\\\n            Collect information from them for you to be able to create a CV for them.\\\\n\\\\n            {json_mode_toggle}\\\\n        '}, {'role': 'user', 'content': 'hi'}]\"]"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**User Messages**: ['{\"json_mode_toggle\": \"\\\\n            Respond in a valid JSON with the following fields (and only them):\\\\n            - \\\\\"ai_message\\\\\": your message (full message including the questions)\\\\n            - \\\\\"status\\\\\", the only possible values:\\\\n                - \\\\\"collecting_missing_information\\\\\": before you\\'ve received the missing information from the human\\\\n                - \\\\\"completed\\\\\": once you\\'ve collected the information\\\\n        \"}']"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**LLM Params**: ['{\"model\": \"mistral-tiny\", \"temperature\": 0, \"n\": 30}'\n",
       " '{\"model\": \"mistral-tiny\", \"temperature\": 0, \"n\": 50}']"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Completions in the experiment**: 80"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Valid JSON's**: 91.25%"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Length (characters)**: 853"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### Variation 2"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Messages template**: [\"[{'role': 'system', 'content': '\\\\n            Act as a professional career consultant with 20 years of experience.\\\\n            \\\\n            Your objective is to help the Human create their CV.\\\\n            \\\\n            Collect information from them for you to be able to create a CV for them.\\\\n\\\\n            {json_mode_toggle}\\\\n        '}, {'role': 'user', 'content': 'hi'}]\"]"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**User Messages**: ['{\"json_mode_toggle\": \"\"}']"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**LLM Params**: ['{\"model\": \"mistral-tiny\", \"temperature\": 0, \"n\": 30}'\n",
       " '{\"model\": \"mistral-tiny\", \"temperature\": 0, \"n\": 50}']"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Completions in the experiment**: 80"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Valid JSON's**: 0.00%"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Length (characters)**: 1515"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ver07_results_nf = experiment.load_results(ver=\"07\")\n",
    "\n",
    "ver07_results_nf.columns\n",
    "\n",
    "ver07_results_nf[\"llm_params\"] = ver07_results_nf[\"llm_params\"].apply(json.dumps)\n",
    "ver07_results_nf[\"data\"] = ver07_results_nf[\"data\"].apply(json.dumps)\n",
    "ver07_results_nf[\"messages_template\"] = ver07_results_nf[\"messages_template\"].apply(str)\n",
    "\n",
    "for i, data in enumerate(ver07_results_nf[\"data\"].unique()):\n",
    "    completions = ver07_results_nf[ver07_results_nf[\"data\"]==data]\n",
    "    usage_df = pd.json_normalize(completions['llm_usage'])\n",
    "    valid_df = pd.json_normalize(completions['assessor.assess_json_valid'].apply(lambda x: json.loads(x) if pd.notnull(x) else x))\n",
    "    len_df = pd.json_normalize(completions['assessor.assess_len'].apply(lambda x: json.loads(x) if pd.notnull(x) else x))\n",
    "    \n",
    "    printmd(f'### Variation {i+1}')\n",
    "    printmd(f'**Messages template**: {list(completions[\"messages_template\"].unique())}')\n",
    "    printmd(f'**User Messages**: {completions[\"data\"].apply(str).unique()}')\n",
    "    printmd(f'**LLM Params**: {completions[\"llm_params\"].apply(str).unique()}')\n",
    "    printmd(f'**Completions in the experiment**: {len(completions)}')\n",
    "    printmd(f'**Valid JSON\\'s**: {len(valid_df[valid_df[\"valid\"]==True])/len(valid_df)*100:.2f}%')#.value_counts(normalize=True).get(True, 0)\n",
    "    printmd(f'**Length (characters)**: {int(len_df[\"len\"].mean())}')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d3c2f3e-927f-4b8e-abed-912825457085",
   "metadata": {},
   "source": [
    "We can see that even the tiny Mistral model is great at outputting a valid json (considering its price and speed you can do additional call when the first json was not valid).\n",
    "\n",
    "Just like in <a href=\"https://github.com/TonySimonovsky/prompt_engineering_experiments/blob/main/experiments/OpenAIAttentionGrab/OpenAI%20Attention%20Grab%20(report).ipynb\">OpenAI gpt-3.5</a>, json output significantly decreases he length of the completion."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
